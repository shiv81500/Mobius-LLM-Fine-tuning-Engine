# CPU-Compatible Models for Low-Memory Systems (Ryzen 5 2500U with 7.8GB RAM)
# These models are small enough to train on CPU with limited memory

# RECOMMENDED FOR YOUR SYSTEM:

# 1. TinyLlama-1.1B (BEST CHOICE - Only 1.1B parameters)
TinyLlama/TinyLlama-1.1B-Chat-v1.0

# 2. Phi-2 (2.7B parameters - Small but capable)
microsoft/phi-2

# 3. Qwen-0.5B (500M parameters - Very lightweight)
Qwen/Qwen-0.5B

# 4. DistilGPT-2 (82M parameters - Ultra lightweight for testing)
distilgpt2

# 5. GPT-2 Small (124M parameters - Good for learning)
gpt2

# AVOID THESE ON YOUR SYSTEM (Too large):
# - meta-llama/Llama-3.2-3B (will use 6GB+ RAM)
# - meta-llama/Llama-3-8B (needs 16GB+ RAM)
# - mistralai/Mistral-7B-v0.2 (needs 14GB+ RAM)
# - microsoft/phi-3-mini (needs 8GB+ RAM)

# Training Tips for CPU:
# - Use batch_size=1
# - Start with 1-2 epochs
# - Use small datasets (100-500 examples max)
# - Training will be SLOW (expect 10-50x slower than GPU)
# - Consider using Google Colab (free GPU) for larger models
